{"relevantArticles":[{"articleTitle":"【NLP】bert入门之分词源码解析","articleAbstractText":"最近做bert模型做分类，涉及到模型上线，需要做文本的编码映射，然后就看了一下bert分词源码，在这里做一下记录 bert编码方法总结： 其实就是分词+分词后的切片映射id 1.分词： 通过BasicTokenizer分词后，遍历每一个分词，将每一个词再经过WordpieceTokenizer分成子串  def tokenize(self, text): split_tokens = [] # 使用BasicTokenizer分词 for token in self.basic_tokenizer.tokenize(text): # 使用WordpieceTokenizer将每一个分词切成子串 for sub_token in self.wordpiece_tokenizer.tokenize(token): split_tokens.append(sub_token)  2.编码： 编码没什么好说的，就是一个切片映射成id的过程，加载词典，将最终的分词结果映射成词典id def convert_by_vocab(vocab, items): \"\"\"Converts a sequenc....","articleStatus":0,"articlePermalink":"/articles/2023/02/23/1677122561047.html","articleImg1URL":"https://b3logfile.com/bing/20190314.jpg?imageView2/1/w/960/h/540/interlace/1/q/100"},{"articleTitle":"【chatgpt】ChatGPT之使用open-ai api实现问答（一）","articleAbstractText":"import os import openai # openai.api_key = os.getenv() openai.api_key = \"sk-******************************\" question = \"Q:什么是神经网络\\n A:\" def generate_prompt(question): return \"\"\"我是一个高度智能的问答机器人。如果你问我一个植根于真理的问题，我会给你答案。如果你问我一个无稽之谈、诡计多端或没有明确答案的问题，我会回答\u201c未知\u201d。\\nQ:{}\\nA:\"\"\".format(question) response = openai.Completion.create( # model=\"text-ada-001\", # model=\"text-curie-001\", # model=\"text-babbage-001\", model=\"text-davinci-003\", # 对话模型的名称 prompt=generate_prompt(question), temperature=1,# 值在[0,1]之间，越大表示回复越....","articleStatus":0,"articlePermalink":"/articles/2023/02/20/1676878924135.html","articleImg1URL":"https://b3logfile.com/bing/20180127.jpg?imageView2/1/w/1280/h/720/interlace/1/q/100"}]}