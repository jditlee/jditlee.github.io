{"relevantArticles":[{"articleTitle":"【bigdata】Flink总结","articleAbstractText":"Flink 几个最基础的概念: Client、JobManager 和 TaskManager。Client 用来提交任务给 JobManager，JobManager 分发任务给 TaskManager 去执行，然后 TaskManager 会心跳的汇报任务状态 窗口： stream.timewindow:时间 stream.countwindow:计数 stream.window(SessionWindows.withGap(Time.minutes(5))：会话 Flink程序的基本构建块是流和转换。 一个程序的基本构成： l 获取execution environment l 加载/创建原始数据 l 指定这些数据的转化方法 l 指定计算结果的存放位置 l 触发程序执行 import&nbsp;org.apache.flink.api.common.functions.FlatMapFunction; import&nbsp;org.apache.flink.api.java.tuple.Tuple2; import&nbsp;org.apache.flink.streaming....","articleStatus":0,"articlePermalink":"/articles/2023/03/16/1678938322285.html","articleImg1URL":"https://b3logfile.com/file/2023/03/solo-fetchupload-3494035270768043777-E6F9Est.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100"},{"articleTitle":"Linux纯命令行配置clash，自由访问GPT api","articleAbstractText":"clash真是难用啊，文档也不好好写，Linux上配置却叫我浏览器访问设置节点。。。 搞了两天终于配置起来了，安装clash的教程基本都千篇一律吧，主要重点在如何命令行配置网络代理，没有一篇教程说明是如何命令行配置的。。。大家服务器都是桌面版的吗，头大 我服务器的操作系统是Ubuntu 安装clash 老三样，下载，解压，安装 # 下载clash，Github地址：https://github.com/Dreamacro/clash/releases # 两种方式： # 1.访问GitHub本地下载了上传到服务器，网络不好的建议此方式 # 2.wget 命令服务器下载 wget https://github.com/Dreamacro/clash/releases/download/v1.16.0/clash-linux-amd64-v1.16.0.gz # 解压 gzip -d clash-linux-amd64-v1.16.0.gz # 解压之后就是二进制执行文件了，不需要安装，修改一下权限，然后执行： # 修改权限 sudo chmod +x clash-linux-amd64-....","articleStatus":0,"articlePermalink":"/articles/2023/05/30/1685437715197.html","articleImg1URL":"https://b3logfile.com/bing/20181112.jpg?imageView2/1/w/960/h/540/interlace/1/q/100"},{"articleTitle":"【bigdata】Hbase总结","articleAbstractText":"架构原理  1）StoreFile 保存实际数据的物理文件，StoreFile 以 HFile 的形式存储在 HDFS 上。每个 Store 会有 一个或多个 StoreFile（HFile），数据在每个 StoreFile 中都是有序的。 2）MemStore 写缓存，由于 HFile 中的数据要求是有序的，所以数据是先存储在 MemStore 中，排好序后，等到达刷写时机才会刷写到HFile，每次刷写都会形成一个新的 HFile。 3）WAL 由于数据要经 MemStore 排序后才能刷写到 HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入MemStore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。 写流程  1）Client 先访问 zookeeper，获取 hbase:meta 表位于哪个 Region Server。 2）访问对应的 Region Server，获取 hbase:meta 表，根据读请求的 namespace:table/rowke....","articleStatus":0,"articlePermalink":"/articles/2023/03/16/1678938058876.html","articleImg1URL":"https://b3logfile.com/file/2023/03/solo-fetchupload-7141292545555375219-g4X2XzM.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100"},{"articleTitle":"【ML】win11+RTX3060搭建tf2.6深度学习环境","articleAbstractText":"win11+RTX3060搭建tf2.6深度学习环境 1.所需软件 cuda cudnn cudnn下载需要注册账号 anaconda tf2.6.2 2.安装cuda cuda简介： CUDA是NVIDIA发明的一种并行计算平台和编程模型。 它可以通过利用图形处理器(GPU)的能力来显著提高计算性能。 CUDA的开发有以下几个设计目标: 1.为标准编程语言(如C)提供一小组扩展，以实现并行算法的直接实现。 2.使用CUDA C/ c++，程序员可以专注于算法的并行化，而不是把时间花在算法的实现上。 3.支持异构计算，应用同时使用CPU和GPU。 应用程序的串行部分运行在CPU上，并行部分被卸载到GPU上， 这样CUDA就可以增量地应用到现有的应用程序上。 CPU和GPU被视为具有各自内存空间的独立设备。 这种配置还允许在CPU和GPU上进行同步计算，而无需争夺内存资源。 cuda支持的GPU有数百个内核，这些内核可以同时运行数千个计算线程。 这些核心拥有共享的资源，包括一个寄存器文件和一个共享的内存。 片上共享内存允许运行在这些核心上的并行任务共享数据，而无需通过系统内存总线发送数据....","articleStatus":0,"articlePermalink":"/articles/2023/03/22/1679472011598.html","articleImg1URL":"https://b3logfile.com/bing/20191112.jpg?imageView2/1/w/1280/h/720/interlace/1/q/100"},{"articleTitle":"【bigdata】3.idea连接虚拟机Hadoop集群","articleAbstractText":"1.windows配置Hadoop环境 1.Linux环境下解压hadoop-2.6.5的tar包 tar -zxvf hadoop-2.6.5.tar.gz，复制解压包到windows的任意目录下 2.下载winutils,copy相应版本bin目录下的winutils.exe和hadoop.dll到解压的Hadoop目录下 3.复制hadoop.dll到C:\\Windows\\System32目录下 4.配置环境变量 4.1配置hadoop_home  4.2Path路径添加hadoop_home/bin 2.maven项目配置Hadoop 1.pom文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project&nbsp;xmlns=\"http://maven.apache.org/POM/4.0.0\" &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" &nbsp....","articleStatus":0,"articlePermalink":"/articles/2023/03/16/1678937003866.html","articleImg1URL":"https://b3logfile.com/file/2023/03/solo-fetchupload-17060812201894802840-cHOlGII.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100"}]}